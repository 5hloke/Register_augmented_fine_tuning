{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcd349b-d6b0-41d3-bfca-27021aec66ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !pip install torch torchvision\n",
    "# !pip install transformers\n",
    "from model import RegBertForQA\n",
    "# !pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387bacf2-da1c-4f64-a57e-b8c18625f2d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from regbertfor QA, num_reg= 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RegBert were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.position_ids', 'bert.reg_pos', 'bert.reg_tokens']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: torch.Size([1, 71])\n",
      "Position_ids: tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "         504, 505, 506, 507, 508, 509, 510, 511]], device='cuda:0')\n",
      "torch.Size([1, 71, 768]) torch.Size([1, 71, 768])\n",
      "input_shape: torch.Size([1, 71])\n",
      "Position_ids: tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
      "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
      "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
      "         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
      "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
      "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
      "         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
      "         504, 505, 506, 507, 508, 509, 510, 511]], device='cuda:0')\n",
      "torch.Size([50, 71, 768]) torch.Size([1, 71, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 50 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 76\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m start_logit \u001b[38;5;241m+\u001b[39m end_logit \n\u001b[1;32m     74\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(forward_func)\n\u001b[0;32m---> 76\u001b[0m attributions, delta \u001b[38;5;241m=\u001b[39m ig\u001b[38;5;241m.\u001b[39mattribute(\n\u001b[1;32m     77\u001b[0m     inputs_embeds,\n\u001b[1;32m     78\u001b[0m     baselines\u001b[38;5;241m=\u001b[39mbaseline_embeds,\n\u001b[1;32m     79\u001b[0m     additional_forward_args\u001b[38;5;241m=\u001b[39m(attention_mask, token_type_ids),\n\u001b[1;32m     80\u001b[0m     return_convergence_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m attributions_sum \u001b[38;5;241m=\u001b[39m attributions\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \n\u001b[1;32m     85\u001b[0m register_token_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[REG\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_registers)]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attribute(\n\u001b[1;32m    287\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    288\u001b[0m         baselines\u001b[38;5;241m=\u001b[39mbaselines,\n\u001b[1;32m    289\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    290\u001b[0m         additional_forward_args\u001b[38;5;241m=\u001b[39madditional_forward_args,\n\u001b[1;32m    291\u001b[0m         n_steps\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[1;32m    292\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_func(\n\u001b[1;32m    352\u001b[0m     forward_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_func,\n\u001b[1;32m    353\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mscaled_features_tpl,\n\u001b[1;32m    354\u001b[0m     target_ind\u001b[38;5;241m=\u001b[39mexpanded_target,\n\u001b[1;32m    355\u001b[0m     additional_forward_args\u001b[38;5;241m=\u001b[39minput_additional_args,\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/captum/_utils/common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func(\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39madditional_forward_args)\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inputs\n\u001b[1;32m    535\u001b[0m )\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mforward_func\u001b[0;34m(inputs_embeds_with_registers, attention_mask_with_registers, token_type_ids_with_registers)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_func\u001b[39m(inputs_embeds_with_registers, attention_mask_with_registers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, token_type_ids_with_registers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     54\u001b[0m         inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds_with_registers,\n\u001b[1;32m     55\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask_with_registers,\n\u001b[1;32m     56\u001b[0m         token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids_with_registers,\n\u001b[1;32m     57\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,  \n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     start_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mstart_logits  \n\u001b[1;32m     60\u001b[0m     end_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mend_logits     \n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Register_augmented_fine_tuning/model.py:246\u001b[0m, in \u001b[0;36mRegBertForQA.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 246\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[1;32m    247\u001b[0m     input_ids,\n\u001b[1;32m    248\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    249\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m    250\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    251\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    252\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    253\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    254\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    255\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# print('outputs[0]',outputs[0].shape)\u001b[39;00m\n\u001b[1;32m    260\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Register_augmented_fine_tuning/model.py:142\u001b[0m, in \u001b[0;36mRegBert.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    140\u001b[0m     register \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_tokens\u001b[38;5;241m.\u001b[39mexpand(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    141\u001b[0m     register \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(register, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg_pos)\n\u001b[0;32m--> 142\u001b[0m     embedding_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((register, input_embeds), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     embedding_output \u001b[38;5;241m=\u001b[39m input_embeds\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 50 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from captum.attr import IntegratedGradients\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('fine_tuned_model_registers_Nov17')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('fine_tuned_model_orig')\n",
    "\n",
    "model_path = 'fine_tuned_model_registers_Nov17'  # Replace with your actual model path\n",
    "# model_path = 'fine_tuned_model_orig'  # Replace with your actual model path\n",
    "\n",
    "model = RegBertForQA.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "question, context = \"What is a way to increase your wound healing speed?\", \\\n",
    "\"Wound care encourages and speeds wound healing via cleaning and protection from reinjury or infection. Depending on each patient's needs, it can range from the simplest first aid to entire nursing specialties such as wound, ostomy, and continence nursing and burn center care.\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "input_ids = inputs['input_ids'].to(device)            \n",
    "token_type_ids = inputs['token_type_ids'].to(device)  \n",
    "attention_mask = inputs['attention_mask'].to(device)  \n",
    "\n",
    "batch_size = input_ids.shape[0]\n",
    "seq_length = input_ids.shape[1]\n",
    "num_registers = model.bert.num_registers\n",
    "\n",
    "inputs_embeds = model.bert.embeddings(\n",
    "    input_ids=input_ids,\n",
    "    token_type_ids=token_type_ids\n",
    ")\n",
    "# raise Exception\n",
    "# register_tokens = model.bert.reg_tokens.expand(batch_size, -1, -1).to(device)\n",
    "# register_pos = model.bert.reg_pos.to(device)\n",
    "# register_embeddings = register_tokens + register_pos  \n",
    "\n",
    "# inputs_embeds_with_registers = torch.cat((register_embeddings, inputs_embeds), dim=1)  # Shape: [batch_size, num_registers + seq_length, embedding_dim]\n",
    "# inputs_embeds_with_registers.requires_grad_()\n",
    "\n",
    "# register_attention_mask = torch.ones((batch_size, num_registers), device=device)\n",
    "# attention_mask_with_registers = torch.cat((register_attention_mask, attention_mask), dim=1)  # Shape: [batch_size, num_registers + seq_length]\n",
    "\n",
    "# register_token_type_ids = torch.zeros((batch_size, num_registers), dtype=token_type_ids.dtype, device=device)\n",
    "# token_type_ids_with_registers = torch.cat((register_token_type_ids, token_type_ids), dim=1)  # Shape: [batch_size, num_registers + seq_length]\n",
    "\n",
    "baseline_embeds = torch.zeros_like(inputs_embeds, device=device)\n",
    "\n",
    "def forward_func(inputs_embeds_with_registers, attention_mask_with_registers=None, token_type_ids_with_registers=None):\n",
    "    outputs = model(\n",
    "        inputs_embeds=inputs_embeds_with_registers,\n",
    "        attention_mask=attention_mask_with_registers,\n",
    "        token_type_ids=token_type_ids_with_registers,\n",
    "        input_ids=input_ids,  \n",
    "    )\n",
    "    start_logits = outputs.start_logits  \n",
    "    end_logits = outputs.end_logits     \n",
    "\n",
    "    start_probs = torch.softmax(start_logits, dim=-1)\n",
    "    end_probs = torch.softmax(end_logits, dim=-1)\n",
    "\n",
    "    start_index = torch.argmax(start_probs, dim=-1) \n",
    "    end_index = torch.argmax(end_probs, dim=-1)     \n",
    "    batch_size = start_logits.shape[0]\n",
    "\n",
    "    start_logit = start_logits[torch.arange(batch_size), start_index]  \n",
    "    end_logit = end_logits[torch.arange(batch_size), end_index]        \n",
    "\n",
    "    return start_logit + end_logit \n",
    "\n",
    "ig = IntegratedGradients(forward_func)\n",
    "\n",
    "attributions, delta = ig.attribute(\n",
    "    inputs_embeds,\n",
    "    baselines=baseline_embeds,\n",
    "    additional_forward_args=(attention_mask, token_type_ids),\n",
    "    return_convergence_delta=True\n",
    ")\n",
    "\n",
    "attributions_sum = attributions.sum(dim=-1)[0]  \n",
    "\n",
    "register_token_ids = ['[REG{}]'.format(i) for i in range(num_registers)]\n",
    "\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n",
    "\n",
    "all_tokens =  register_token_ids + input_tokens\n",
    "\n",
    "print(\"Number of tokens:\", len(all_tokens))\n",
    "print(\"Number of attributions:\", len(attributions_sum))\n",
    "\n",
    "for token, attribution in zip(all_tokens, attributions_sum):\n",
    "    print(f'{token}: {attribution.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b4746-e298-4bab-b0ce-70e0b550cc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "attributions_np = attributions_sum.detach().cpu().numpy()\n",
    "attributions_norm = attributions_np / np.linalg.norm(attributions_np)\n",
    "\n",
    "outputs = model(\n",
    "    inputs_embeds=inputs_embeds_with_registers,\n",
    "    attention_mask=attention_mask_with_registers,\n",
    "    token_type_ids=token_type_ids_with_registers,\n",
    "    input_ids=None,\n",
    ")\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "start_probs = torch.softmax(start_logits, dim=-1)\n",
    "end_probs = torch.softmax(end_logits, dim=-1)\n",
    "\n",
    "start_index = torch.argmax(start_probs, dim=-1).item()\n",
    "end_index = torch.argmax(end_probs, dim=-1).item()\n",
    "\n",
    "adjusted_start_index = max(0, start_index - num_registers)\n",
    "adjusted_end_index = max(0, end_index - num_registers)\n",
    "\n",
    "pred_prob = ((start_probs[0, start_index] + end_probs[0, end_index]) / 2).item()\n",
    "\n",
    "answer_ids = input_ids[0, adjusted_start_index: adjusted_end_index + 1]\n",
    "answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids)\n",
    "predicted_answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "vis_data_record = viz.VisualizationDataRecord(\n",
    "    word_attributions=attributions_norm,\n",
    "    pred_prob=pred_prob,\n",
    "    pred_class=predicted_answer,\n",
    "    true_class=\"\",  \n",
    "    attr_class=\"\",\n",
    "    attr_score=attributions_norm.sum(),\n",
    "    raw_input_ids=all_tokens,\n",
    "    convergence_score=delta.item()\n",
    ")\n",
    "\n",
    "# Visualize attributions\n",
    "viz.visualize_text([vis_data_record])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e227899-8e32-4dce-a171-fe5a8d12dfae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb81cf2-3c34-42ce-b76f-a0d071a544f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33eb689-995f-4d58-abfc-2d6f22f92b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed0add-2b7c-4da5-87a4-f6afa36fe39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a5e1b-eb4b-4f47-b8d5-aba3db8af19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd1305-8fbc-429d-978f-9f898b9bb0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670e932-436a-4f08-aa50-cddf5854511b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Obtain attention weights from the model\n",
    "outputs = model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    token_type_ids=token_type_ids,\n",
    "    output_attentions=True\n",
    ")\n",
    "\n",
    "attentions = outputs.attentions  # A tuple of attention matrices\n",
    "\n",
    "# Visualize attention for a specific layer and head\n",
    "import seaborn as sns\n",
    "\n",
    "layer = 0  # Choose the layer to analyze\n",
    "head = 0   # Choose the head\n",
    "\n",
    "attention_weights = attentions[layer][0][head].detach().cpu().numpy()\n",
    "sns.heatmap(attention_weights)\n",
    "plt.title(f'Attention Weights - Layer {layer+1}, Head {head+1}')\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Tokens')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335ffd6-77ac-46d4-bbb6-88c96bc61138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8b230-a471-4e13-a44c-67b20a00a017",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from captum.attr import IntegratedGradients\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('fine_tuned_model')\n",
    "\n",
    "model_path = 'fine_tuned_model'  \n",
    "model = RegBertForQA.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "question, context = (\n",
    "    \"How long is the Great Wall of China?\",\n",
    "    \"The Great Wall of China is an ancient wall in China. The wall was built to protect the northern borders of the Chinese Empire from invading nomadic tribes. The Great Wall stretches from Dandong in the east to Lop Lake in the west, covering about 13,000 miles.\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "input_ids = inputs['input_ids'].to(device)\n",
    "token_type_ids = inputs['token_type_ids'].to(device)\n",
    "attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "# Prepare inputs_embeds with register tokens\n",
    "batch_size = input_ids.shape[0]\n",
    "seq_length = input_ids.shape[1]\n",
    "num_registers = model.bert.num_registers\n",
    "\n",
    "inputs_embeds = model.bert.embeddings(\n",
    "    input_ids=input_ids,\n",
    "    token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "register_tokens = model.bert.reg_tokens.expand(batch_size, -1, -1).to(device)\n",
    "register_pos = model.bert.reg_pos.to(device)\n",
    "register_embeddings = register_tokens + register_pos\n",
    "\n",
    "inputs_embeds_with_registers = torch.cat((register_embeddings, inputs_embeds), dim=1)  # Shape: [batch_size, num_registers + seq_length, embedding_dim]\n",
    "inputs_embeds_with_registers.requires_grad_()\n",
    "\n",
    "# Extend attention masks\n",
    "register_attention_mask = torch.ones((batch_size, num_registers), device=device)\n",
    "attention_mask_with_registers = torch.cat((register_attention_mask, attention_mask), dim=1)\n",
    "\n",
    "register_token_type_ids = torch.zeros((batch_size, num_registers), dtype=token_type_ids.dtype, device=device)\n",
    "token_type_ids_with_registers = torch.cat((register_token_type_ids, token_type_ids), dim=1)\n",
    "\n",
    "# Baseline embeddings (zeros or padding embeddings)\n",
    "baseline_embeds = torch.zeros_like(inputs_embeds_with_registers, device=device)\n",
    "\n",
    "# Define forward function\n",
    "def forward_func(inputs_embeds_with_registers, attention_mask_with_registers=None, token_type_ids_with_registers=None, target=None):\n",
    "    outputs = model(\n",
    "        inputs_embeds=inputs_embeds_with_registers,\n",
    "        attention_mask=attention_mask_with_registers,\n",
    "        token_type_ids=token_type_ids_with_registers,\n",
    "        input_ids=None,  # Not passing input_ids since embeddings are provided\n",
    "    )\n",
    "    start_logits = outputs.start_logits  # Shape: [batch_size, seq_length]\n",
    "    end_logits = outputs.end_logits      # Shape: [batch_size, seq_length]\n",
    "    \n",
    "    # Return logits for the specific target index\n",
    "    if target is not None:\n",
    "        return start_logits[:, target] if target == 0 else end_logits[:, target]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid target value. Must be 0 (start logits) or 1 (end logits).\")\n",
    "\n",
    "# Define Integrated Gradients\n",
    "ig = IntegratedGradients(forward_func)\n",
    "\n",
    "# Get predicted start and end indices\n",
    "start_index = torch.argmax(model(input_ids=input_ids).start_logits, dim=-1)\n",
    "end_index = torch.argmax(model(input_ids=input_ids).end_logits, dim=-1)\n",
    "\n",
    "# Compute attributions for start logits\n",
    "start_attributions, start_delta = ig.attribute(\n",
    "    inputs_embeds_with_registers,\n",
    "    baselines=baseline_embeds,\n",
    "    additional_forward_args=(attention_mask_with_registers, token_type_ids_with_registers, start_index.item()),  # Target = predicted start index\n",
    "    return_convergence_delta=True\n",
    ")\n",
    "\n",
    "# Compute attributions for end logits\n",
    "end_attributions, end_delta = ig.attribute(\n",
    "    inputs_embeds_with_registers,\n",
    "    baselines=baseline_embeds,\n",
    "    additional_forward_args=(attention_mask_with_registers, token_type_ids_with_registers, end_index.item()),  # Target = predicted end index\n",
    "    return_convergence_delta=True\n",
    ")\n",
    "\n",
    "# Sum attributions across embedding dimensions\n",
    "start_attributions_sum = start_attributions.sum(dim=-1)[0]\n",
    "end_attributions_sum = end_attributions.sum(dim=-1)[0]\n",
    "\n",
    "# Combine tokens (register + input tokens)\n",
    "register_token_ids = ['[REG{}]'.format(i) for i in range(num_registers)]\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0))\n",
    "all_tokens = register_token_ids + input_tokens\n",
    "\n",
    "# Print attributions\n",
    "print(\"Token-Level Attributions for Start Logits:\")\n",
    "for token, attribution in zip(all_tokens, start_attributions_sum):\n",
    "    print(f\"{token}: {attribution.item()}\")\n",
    "\n",
    "print(\"\\nToken-Level Attributions for End Logits:\")\n",
    "for token, attribution in zip(all_tokens, end_attributions_sum):\n",
    "    print(f\"{token}: {attribution.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44835c9-57c1-4411-b298-5f0d9a2cf818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "# Convert attributions to numpy and normalize\n",
    "start_attributions_np = start_attributions_sum.detach().cpu().numpy()\n",
    "end_attributions_np = end_attributions_sum.detach().cpu().numpy()\n",
    "\n",
    "start_attributions_norm = start_attributions_np / np.linalg.norm(start_attributions_np)\n",
    "end_attributions_norm = end_attributions_np / np.linalg.norm(end_attributions_np)\n",
    "\n",
    "# Get model outputs\n",
    "outputs = model(\n",
    "    inputs_embeds=inputs_embeds_with_registers,\n",
    "    attention_mask=attention_mask_with_registers,\n",
    "    token_type_ids=token_type_ids_with_registers,\n",
    "    input_ids=None,\n",
    ")\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "start_probs = torch.softmax(start_logits, dim=-1)\n",
    "end_probs = torch.softmax(end_logits, dim=-1)\n",
    "\n",
    "start_index = torch.argmax(start_probs, dim=-1).item()\n",
    "end_index = torch.argmax(end_probs, dim=-1).item()\n",
    "\n",
    "# Adjust indices for register tokens\n",
    "adjusted_start_index = max(0, start_index - num_registers)\n",
    "adjusted_end_index = max(0, end_index - num_registers)\n",
    "\n",
    "# Get predicted answer\n",
    "answer_ids = input_ids[0, adjusted_start_index: adjusted_end_index + 1]\n",
    "answer_tokens = tokenizer.convert_ids_to_tokens(answer_ids)\n",
    "predicted_answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "# Visualize attributions for start and end logits\n",
    "start_vis_data_record = viz.VisualizationDataRecord(\n",
    "    word_attributions=start_attributions_norm,\n",
    "    pred_prob=start_probs[0, start_index].item(),\n",
    "    pred_class=predicted_answer,\n",
    "    true_class=\"\",  # Provide true answer if available\n",
    "    attr_class=\"Start Logits\",\n",
    "    attr_score=start_attributions_norm.sum(),\n",
    "    raw_input_ids=all_tokens,\n",
    "    convergence_score=start_delta.item()\n",
    ")\n",
    "\n",
    "end_vis_data_record = viz.VisualizationDataRecord(\n",
    "    word_attributions=end_attributions_norm,\n",
    "    pred_prob=end_probs[0, end_index].item(),\n",
    "    pred_class=predicted_answer,\n",
    "    true_class=\"\",  # Provide true answer if available\n",
    "    attr_class=\"End Logits\",\n",
    "    attr_score=end_attributions_norm.sum(),\n",
    "    raw_input_ids=all_tokens,\n",
    "    convergence_score=end_delta.item()\n",
    ")\n",
    "\n",
    "# Visualize both start and end attributions\n",
    "viz.visualize_text([start_vis_data_record, end_vis_data_record])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39102053-7b83-449e-b137-3c60c0606471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3152787-4127-4723-8064-91b57bd6e786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551c3f5-fc6e-4dee-8999-60516a698212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
